{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2200e300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "from awsglue.transforms import *\n",
    "from awsglue.utils import getResolvedOptions\n",
    "from pyspark.context import SparkContext\n",
    "from awsglue.context import GlueContext\n",
    "from awsglue.job import Job\n",
    "from awsglue.transforms import *\n",
    "import ast\n",
    "from io import StringIO\n",
    "import boto3\n",
    "from pyspark.sql.functions import year, col\n",
    "from awsglue.dynamicframe import DynamicFrame\n",
    "\n",
    "\n",
    "### below just for testing - not required if creating glue job script and deploying\n",
    "sys.argv = [sys.argv[0]]\n",
    "arg_vals = ['--JOB_NAME=test','--database=default','--table=sample_manning_csv','--destination=s3://aws-forecast-demo-examples/','--year_range=[2010, 2014]']\n",
    "sys.argv.extend(arg_vals)\n",
    "\n",
    "args = getResolvedOptions(sys.argv, ['JOB_NAME', 'database', 'table','destination', 'year_range'])\n",
    "glueContext = GlueContext(SparkContext.getOrCreate())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8bafa7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    assert len(ast.literal_eval(args['year_range'])) == 2 \n",
    "except AssertionError as e:\n",
    "        raise ValueError(f\"--year_range needs to have two values in str list passed as arg '[lower_year, upper_year]'.\\\n",
    "You passed in '{args['year_range']}'\")\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc4f69",
   "metadata": {},
   "source": [
    "#### Create dynamic dataframe from glue data catalog table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "da997268",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 2905\n",
      "root\n",
      "|-- index: long\n",
      "|-- ds: string\n",
      "|-- y: double"
     ]
    }
   ],
   "source": [
    "# if enabling glue job bookmark, need to pass in transformation_ctx for bookmark to track dataframe states\n",
    "\n",
    "ts_dyf = glueContext.create_dynamic_frame.from_catalog(database=\"default\", table_name=\"sample_manning_csv\", transformation_ctx = \"read data from S3\")\n",
    "print(\"Count: \" + str(ts_dyf.count()))\n",
    "ts_dyf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837feaf4",
   "metadata": {},
   "source": [
    "#### Check schema inferred by spark when reading directly from S3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e26b9211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: integer (nullable = true)\n",
      " |-- ds: timestamp (nullable = true)\n",
      " |-- y: double (nullable = true)"
     ]
    }
   ],
   "source": [
    "ts_df = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\", \"true\").load(\n",
    "   's3://aws-forecast-demo-examples/sample_manning.csv')\n",
    "ts_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682d590f",
   "metadata": {},
   "source": [
    "The glue crawler used to create the catalog table has inferred the ds column as string whilst we need it in timestamp\n",
    "format for AWS forecast. Index column will be dropped anyway so it is irrelevant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87705d54",
   "metadata": {},
   "source": [
    "#### Drop index field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "28479abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+\n",
      "|        ds|               y|\n",
      "+----------+----------------+\n",
      "|2007-12-10|9.59076113897809|\n",
      "|2007-12-11|8.51959031601596|\n",
      "|2007-12-12|8.18367658262066|\n",
      "|2007-12-13|8.07246736935477|\n",
      "|2007-12-14| 7.8935720735049|\n",
      "|2007-12-15|7.78364059622125|\n",
      "|2007-12-16|8.41405243249672|\n",
      "|2007-12-17|8.82922635473185|\n",
      "|2007-12-18|8.38251828808963|\n",
      "|2007-12-19|8.06965530688617|\n",
      "|2007-12-20|7.87929148508227|\n",
      "|2007-12-21|7.76174498465891|\n",
      "|2007-12-22|7.52940645783701|\n",
      "|2007-12-23|8.38526052015541|\n",
      "|2007-12-24|8.62011072542292|\n",
      "|2007-12-25|7.85243908535751|\n",
      "|2007-12-26|7.85399308722424|\n",
      "|2007-12-27| 8.0519780789023|\n",
      "|2007-12-28|7.92660259918138|\n",
      "|2007-12-29|7.83834331555712|\n",
      "+----------+----------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "dyf_dropped = DropFields.apply(frame=ts_dyf , paths=[\"index\"], transformation_ctx = \"drop index columnn\")\n",
    "dyf_dropped.toDF().show()\n",
    "#dyf_dropped = ts_dyf.rename_field('ds', 'timestamp').rename_field('y', 'target_value').drop_fields(['index'])\n",
    "#dyf_dropped.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b56fa8e",
   "metadata": {},
   "source": [
    "#### Rename columns and cast "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e37ff186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------+\n",
      "|          timestamp|    target_value|\n",
      "+-------------------+----------------+\n",
      "|2007-12-10 00:00:00|9.59076113897809|\n",
      "|2007-12-11 00:00:00|8.51959031601596|\n",
      "|2007-12-12 00:00:00|8.18367658262066|\n",
      "|2007-12-13 00:00:00|8.07246736935477|\n",
      "|2007-12-14 00:00:00| 7.8935720735049|\n",
      "|2007-12-15 00:00:00|7.78364059622125|\n",
      "|2007-12-16 00:00:00|8.41405243249672|\n",
      "|2007-12-17 00:00:00|8.82922635473185|\n",
      "|2007-12-18 00:00:00|8.38251828808963|\n",
      "|2007-12-19 00:00:00|8.06965530688617|\n",
      "|2007-12-20 00:00:00|7.87929148508227|\n",
      "|2007-12-21 00:00:00|7.76174498465891|\n",
      "|2007-12-22 00:00:00|7.52940645783701|\n",
      "|2007-12-23 00:00:00|8.38526052015541|\n",
      "|2007-12-24 00:00:00|8.62011072542292|\n",
      "|2007-12-25 00:00:00|7.85243908535751|\n",
      "|2007-12-26 00:00:00|7.85399308722424|\n",
      "|2007-12-27 00:00:00| 8.0519780789023|\n",
      "|2007-12-28 00:00:00|7.92660259918138|\n",
      "|2007-12-29 00:00:00|7.83834331555712|\n",
      "+-------------------+----------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "dyf_applyMapping = ApplyMapping.apply( frame = dyf_dropped, mappings = [ (\"ds\",\"String\",\"timestamp\",\"timestamp\"),\\\n",
    "(\"y\",\"double\", \"target_value\", \"double\") ], transformation_ctx = \"rename and cast columns\")\n",
    "dyf_applyMapping.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff51bff",
   "metadata": {},
   "source": [
    "#### Convert to Dynamic DF to pyspark df to use spark filter operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6e8e3151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------------+\n",
      "|          timestamp|    target_value|\n",
      "+-------------------+----------------+\n",
      "|2011-01-01 00:00:00|9.00969189848934|\n",
      "|2011-01-02 00:00:00|9.39897529082673|\n",
      "|2011-01-03 00:00:00|9.99392223000734|\n",
      "|2011-01-04 00:00:00|9.06149227523977|\n",
      "|2011-01-05 00:00:00|8.97119446318447|\n",
      "|2011-01-06 00:00:00|8.94689552388845|\n",
      "|2011-01-07 00:00:00|9.18696938565294|\n",
      "|2011-01-08 00:00:00| 9.0980671294934|\n",
      "|2011-01-09 00:00:00|10.8781037947059|\n",
      "|2011-01-10 00:00:00|9.38269576445829|\n",
      "|2011-01-11 00:00:00|9.19897604189713|\n",
      "|2011-01-12 00:00:00|8.62119278143472|\n",
      "|2011-01-13 00:00:00|8.61323037961318|\n",
      "|2011-01-14 00:00:00|8.69517199877606|\n",
      "|2011-01-15 00:00:00|8.72029728739272|\n",
      "|2011-01-16 00:00:00|9.50031980347665|\n",
      "|2011-01-17 00:00:00|9.34757739028127|\n",
      "|2011-01-18 00:00:00|8.78370269863522|\n",
      "|2011-01-19 00:00:00|8.70217786562968|\n",
      "|2011-01-20 00:00:00| 8.6821990260005|\n",
      "+-------------------+----------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "filter_years = ast.literal_eval(args['year_range'])\n",
    "\n",
    "filtered_df = dyf_applyMapping.toDF().filter((year(col(\"timestamp\")) > filter_years[0]) & (year(col(\"timestamp\")) < filter_years[1]))\n",
    "filtered_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbd6476",
   "metadata": {},
   "source": [
    "#### Write to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0010ba",
   "metadata": {},
   "source": [
    "Convert back to Dynamic DF first before  writing the final output to S3 destination path passed through args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "40de09d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_dyf = DynamicFrame.fromDF(filtered_df.repartition(1), glueContext, \"final_dyf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "a636a722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<awsglue.dynamicframe.DynamicFrame object at 0x7f20d83f5ac8>"
     ]
    }
   ],
   "source": [
    "glueContext.write_dynamic_frame.from_options(\n",
    "       frame = final_dyf,\n",
    "       connection_type = \"s3\",\n",
    "       connection_options = {\"path\": args['destination']},\n",
    "       format = \"csv\",transformation_ctx = \"S3 upload\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da426b70",
   "metadata": {},
   "source": [
    "#### Rename glue output filename in S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfa8205",
   "metadata": {},
   "source": [
    "By default write operation from glue renames file to random name based on job id. To rename, we have to do this manually by reading from S3 and then put object with another key\n",
    "\n",
    "Data read from s3 is botocore streaming body object so need to decode bytes to csv string format\n",
    "To read via pd.read_csv convert to in memory text stream object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2774e8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run-1652665904728-part-r-00000', 'run-1652669891142-part-r-00000']\n",
      "2022-05-16 02:58:21+00:00"
     ]
    }
   ],
   "source": [
    "bucket = args['destination'].split('//')[-1].rstrip('/')\n",
    "\n",
    "client = boto3.client('s3')\n",
    "response = client.list_objects(\n",
    "    Bucket=bucket,\n",
    "    Prefix='run-'\n",
    ")\n",
    "\n",
    "objects = [item['Key'] for item in response['Contents']]\n",
    "print(objects)\n",
    "max_date = max([item['LastModified'] for item in response['Contents']])\n",
    "print(max_date)\n",
    "for item in response['Contents']:\n",
    "    if item['LastModified'] == max_date:\n",
    "        key = item['Key']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5e009d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               timestamp  target_value\n",
      "0  2011-01-01 00:00:00.0      9.009692\n",
      "1  2011-01-02 00:00:00.0      9.398975\n",
      "2  2011-01-03 00:00:00.0      9.993922\n",
      "3  2011-01-04 00:00:00.0      9.061492\n",
      "4  2011-01-05 00:00:00.0      8.971194\n",
      "5  2011-01-06 00:00:00.0      8.946896\n",
      "6  2011-01-07 00:00:00.0      9.186969\n",
      "7  2011-01-08 00:00:00.0      9.098067\n",
      "8  2011-01-09 00:00:00.0     10.878104\n",
      "9  2011-01-10 00:00:00.0      9.382696"
     ]
    }
   ],
   "source": [
    "response = client.get_object(Bucket='aws-forecast-demo-examples',Key=key)\n",
    "bytes_data = response['Body'].read()\n",
    "csv_string = bytes_data.decode()\n",
    "pd.read_csv(StringIO(csv_str)).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "76dbe859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming file run-1652669891142-part-r-00000 to glue_prep_aws_forecast.csv\n",
      "{'ResponseMetadata': {'RequestId': 'HV91JPZYN9ANRWDD', 'HostId': 'bCMUQXf8VUeeVkBnUEu9gOa33HXY4niHd4Ia5VZrsCI1jMwNVdgnMCznBQTwA5HCte2X07pwxss=', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amz-id-2': 'bCMUQXf8VUeeVkBnUEu9gOa33HXY4niHd4Ia5VZrsCI1jMwNVdgnMCznBQTwA5HCte2X07pwxss=', 'x-amz-request-id': 'HV91JPZYN9ANRWDD', 'date': 'Mon, 16 May 2022 04:12:44 GMT', 'etag': '\"d7c0b11b765cc0f54a63783ff165775c\"', 'server': 'AmazonS3', 'content-length': '0'}, 'RetryAttempts': 0}, 'ETag': '\"d7c0b11b765cc0f54a63783ff165775c\"'}"
     ]
    }
   ],
   "source": [
    "renamed = 'glue_prep_aws_forecast.csv'\n",
    "print(f\"Renaming file {key} to {renamed}\")\n",
    "client.put_object(Body=bytes_data, Bucket=bucket, Key=renamed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90291bdf",
   "metadata": {},
   "source": [
    "Delete original glue output object after renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "50c3171e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': 'AYGZYQWPWH8X31EB', 'HostId': 'qCqKD7iVytMr3XGhTwXsW5nBKtd2906YfHD/GXrjX44HEz4iErl0mz7dSoLdahXPoEfNAG3czCQ=', 'HTTPStatusCode': 204, 'HTTPHeaders': {'x-amz-id-2': 'qCqKD7iVytMr3XGhTwXsW5nBKtd2906YfHD/GXrjX44HEz4iErl0mz7dSoLdahXPoEfNAG3czCQ=', 'x-amz-request-id': 'AYGZYQWPWH8X31EB', 'date': 'Mon, 16 May 2022 04:09:13 GMT', 'server': 'AmazonS3'}, 'RetryAttempts': 0}}\n",
      "{'ResponseMetadata': {'RequestId': 'AYGQW5WEYT31SSMZ', 'HostId': '1xM+px/2M5OcY6tK2T3yx0PwHoK2PSsvb7sLnqCrHxxtnOSmotUDmue/Zfva/itSeZaKi29WLDA=', 'HTTPStatusCode': 204, 'HTTPHeaders': {'x-amz-id-2': '1xM+px/2M5OcY6tK2T3yx0PwHoK2PSsvb7sLnqCrHxxtnOSmotUDmue/Zfva/itSeZaKi29WLDA=', 'x-amz-request-id': 'AYGQW5WEYT31SSMZ', 'date': 'Mon, 16 May 2022 04:09:13 GMT', 'server': 'AmazonS3'}, 'RetryAttempts': 0}}"
     ]
    }
   ],
   "source": [
    "\n",
    "for item in objects:\n",
    "    client.delete_object(Bucket=bucket, Key=item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
